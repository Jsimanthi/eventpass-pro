# Fluentd configuration for EventPass Pro log aggregation

# Source: Read logs from Docker containers
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# Source: Monitor log files
<source>
  @type tail
  path /var/log/eventpass/*.log
  pos_file /var/log/fluentd/eventpass.log.pos
  tag eventpass.file
  <parse>
    @type json
  </parse>
  refresh_interval 5s
</source>

# Filter: Add Kubernetes metadata if running in K8s
<filter eventpass.**>
  @type record_transformer
  enable_ruby true
  <record>
    service eventpass
    environment ${ENVIRONMENT:-development}
  </record>
</filter>

# Match: Route logs to Elasticsearch
<match eventpass.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  index_name eventpass-${tag}-%Y.%m.%d
  type_name fluentd
  <buffer>
    @type memory
    flush_interval 10s
  </buffer>
</match>

# Match: Route error logs to separate index
<match eventpass.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  index_name eventpass-errors-${tag}-%Y.%m.%d
  type_name fluentd
  <buffer>
    @type memory
    flush_interval 5s
  </buffer>
</match>

# Match: Send logs to Prometheus for metrics
<match eventpass.**>
  @type prometheus
  <metric>
    name eventpass_logs_total
    type counter
    desc Number of log entries
    <labels>
      tag ${tag}
      level ${record['level']}
    </labels>
  </metric>
</match>

# Match: Send critical logs to Slack/PagerDuty
<match eventpass.error>
  @type slack
  webhook_url ${SLACK_WEBHOOK_URL}
  channel alert-channel
  username fluentd
  <buffer>
    @type memory
    flush_interval 30s
  </buffer>
</match>